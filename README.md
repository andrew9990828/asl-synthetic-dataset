ğŸš€ ASL Abstract Synthetic Dataset + CNN Pipeline

Author: Andrew Bieber
Focus Areas: Synthetic Data â€¢ Deep Learning â€¢ Computer Vision â€¢ Procedural Generation

â­ Overview

This project generates a fully synthetic ASL (American Sign Language) dataset using procedural graphics, geometric variation, and heavy image augmentations â€” then trains a compact dual-head CNN to classify letters and estimate a synthetic distance scalar.

You get:

A synthetic dataset generator

A PyTorch dataset loader

A compact dual-head CNN

A full training loop

Jupyter notebooks for dataset exploration + embedding visualization

This project demonstrates modern dataset engineering and end-to-end ML experimentation in a clean, reproducible pipeline.

ğŸš€ Quick Start Guide
1ï¸âƒ£ Clone the repository
git clone https://github.com/andrew9990828/asl-synthetic-dataset.git
cd asl-synthetic-dataset

2ï¸âƒ£ Create and activate a virtual environment
Windows:
python -m venv venv
venv\Scripts\activate

Mac/Linux:
python3 -m venv venv
source venv/bin/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Generate the synthetic dataset
python generate_dataset.py


This will create:

asl_abstract_dataset/
    A/
        A_00000.png
        A_00001.png
    B/
        ...
    labels.xlsx


Total size depends on IMAGES_PER_LETTER in generate_dataset.py.

5ï¸âƒ£ Train the CNN model
python train_model.py


You will see epoch loss values.

The final model is saved as:

asl_model.pt

6ï¸âƒ£ Explore the generated dataset
jupyter notebook


Open:

notebooks/explore_dataset.ipynb

7ï¸âƒ£ Visualize embeddings (TSNE)

Open:

notebooks/visualize_embeddings.ipynb


This notebook will later include:

TSNE projections

Distance vs class separation plots

Embedding space debugging tools

ğŸ“¦ Project Structure
asl-synthetic-dataset/
â”‚
â”œâ”€â”€ asl_abstract_dataset/         
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ explore_dataset.ipynb     
â”‚   â””â”€â”€ visualize_embeddings.ipynb 
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â”œâ”€â”€ augmentations.py      
â”‚   â”‚   â”œâ”€â”€ shapes.py             
â”‚   â”‚   â””â”€â”€ dataset_loader.py     
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ metrics.py            
â”‚   â”‚   â””â”€â”€ train_utils.py        
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚       â””â”€â”€ small_cnn.py          
â”‚
â”œâ”€â”€ generate_dataset.py           
â”œâ”€â”€ train_model.py                
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ§  How the Pipeline Works
1. Procedural Graphics

Each letter Aâ€“Z corresponds to one procedural pattern style:

line clusters

arcs

rectangular pillars

radial spokes

Each image is randomized by:

rotation

blur

Perlin-like noise

background jitter

scale tied to a synthetic â€œdistanceâ€ label

2. Dual-Head CNN

The model predicts:

Letter class (26-way classification)

Distance scalar (regression)

Loss:

CE(class) + 0.25 * MSE(distance)

3. Fully Reproducible Training

A ~15-line clean training script trains everything end-to-end.

ğŸ“Œ Notes for Researchers

This repo is ideal for:

experimenting with synthetic data

training small CNNs

embedding visualization

building reproducible ML demos

teaching fundamentals

Possible expansions:

Vision Transformers

Contrastive learning

Latent-space clustering

Memory-augmented models

ğŸ‰ Final Notes

If you improve this dataset, add shapes, or upgrade the model â€” feel free to submit a PR.

Happy building!